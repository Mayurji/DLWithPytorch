{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = t.Compose(\n",
    "            [t.ToTensor(),\n",
    "            t.Normalize((0.5,),(0.5,))]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.FashionMNIST(\n",
    "            './data', download=True, train=True, transform=transform\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                        shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                        shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('runs/fashion_mnist_experiment_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "\n",
    "writer.add_image('four_fashion_mnist_images',img_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(net, images)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorboard as tb\n",
    "import tensorflow as tf\n",
    "tf.io.gfile = tb.compat.tensorflow_stub.io.gfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "def select_n_random(data, labels, n=100):\n",
    "    \n",
    "    assert len(data) == len(labels)\n",
    "    \n",
    "    perm = torch.randperm(len(data))\n",
    "    return data[perm][:n], labels[perm][:n]\n",
    "\n",
    "images, labels = select_n_random(trainset.data, trainset.targets)\n",
    "class_labels = [classes[lab] for lab in labels]\n",
    "\n",
    "features = images.view(-1, 28 * 28)\n",
    "writer.add_embedding(features, \n",
    "                    metadata=class_labels,\n",
    "                    label_img=images.unsqueeze(1))\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            classes[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            classes[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:    # every 1000 mini-batches...\n",
    "\n",
    "            # ...log the running loss\n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 1000,\n",
    "                            epoch * len(trainloader) + i)\n",
    "\n",
    "            # ...log a Matplotlib Figure showing the model's predictions on a\n",
    "            # random mini-batch\n",
    "            writer.add_figure('predictions vs. actuals',\n",
    "                            plot_classes_preds(net, inputs, labels),\n",
    "                            global_step=epoch * len(trainloader) + i)\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. gets the probability predictions in a test_size x num_classes Tensor\n",
    "# 2. gets the preds in a test_size Tensor\n",
    "# takes ~10 seconds to run\n",
    "class_probs = []\n",
    "class_preds = []\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        output = net(images)\n",
    "        class_probs_batch = [F.softmax(el, dim=0) for el in output]\n",
    "        _, class_preds_batch = torch.max(output, 1)\n",
    "\n",
    "        class_probs.append(class_probs_batch)\n",
    "        class_preds.append(class_preds_batch)\n",
    "\n",
    "test_probs = torch.cat([torch.stack(batch) for batch in class_probs])\n",
    "test_preds = torch.cat(class_preds)\n",
    "\n",
    "# helper function\n",
    "def add_pr_curve_tensorboard(class_index, test_probs, test_preds, global_step=0):\n",
    "    '''\n",
    "    Takes in a \"class_index\" from 0 to 9 and plots the corresponding\n",
    "    precision-recall curve\n",
    "    '''\n",
    "    tensorboard_preds = test_preds == class_index\n",
    "    tensorboard_probs = test_probs[:, class_index]\n",
    "\n",
    "    writer.add_pr_curve(classes[class_index],\n",
    "                        tensorboard_preds,\n",
    "                        tensorboard_probs,\n",
    "                        global_step=global_step)\n",
    "    writer.close()\n",
    "\n",
    "# plot all the pr curves\n",
    "for i in range(len(classes)):\n",
    "    add_pr_curve_tensorboard(i, test_probs, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([2.7430e-04, 9.9473e-01, 1.3021e-04, 3.7905e-03, 5.7206e-04, 1.2377e-04,\n",
       "         2.4042e-04, 2.4360e-05, 1.0694e-04, 7.4813e-06]),\n",
       " tensor([6.0336e-03, 4.9515e-06, 4.5841e-04, 4.8641e-03, 3.8601e-04, 2.5534e-03,\n",
       "         7.4621e-04, 1.0399e-04, 9.8478e-01, 6.4696e-05]),\n",
       " tensor([5.4230e-05, 9.9924e-01, 3.9484e-05, 4.2206e-04, 1.2924e-04, 4.4855e-05,\n",
       "         4.3127e-05, 6.4155e-06, 2.3061e-05, 1.2747e-06]),\n",
       " tensor([3.5191e-04, 1.5455e-04, 1.6436e-03, 2.0231e-04, 4.1580e-04, 9.3877e-01,\n",
       "         1.3540e-04, 4.2784e-02, 1.1210e-02, 4.3328e-03])]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_probs_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 8, 1, 5])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_preds_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
