{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch\n",
    "\n",
    "PyTorch is a popular open source machine learning library based on Torch library. Pytorch provides three set of libraries, i.e., torchvision, torchaudio, torchtext for Computer Vision, Audio and Text respectively.\n",
    "\n",
    "It provides two high-level features:\n",
    "\n",
    "* Tensor computation (like NumPy) with strong GPU acceleration\n",
    "* Deep neural networks built on a type-based autograd system\n",
    "\n",
    "### Topics Covered\n",
    "\n",
    "* **Named Tensors**\n",
    "\n",
    "   - How To Declare Named Dimensions?\n",
    "   - Manipulating Using Named Dimensions.\n",
    "   - Renaming Dimensions.\n",
    "\n",
    "* **Tensor Storage**\n",
    "\n",
    "   - View Storage Object Of A Tensor.\n",
    "   - Accessing Storage Location And Modifying Value Of A Tensor.\n",
    "   - Storage Offset.\n",
    "   \n",
    "* **Stride**\n",
    "\n",
    "   - Find the Stride of a Tensor.\n",
    "   - Storage and Stride.\n",
    "   - Accessing Elements Using Stride and Index.\n",
    "   - Comparing Index and Stride Based Element."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open('SampleImages/dog.jpg')\n",
    "np_image = np.rollaxis(np.asarray(image), 2, 0)\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Tensor\n",
    "\n",
    "* It assigns name to dimension and can make calculation using those names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How To Declare Named Dimensions?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Consider the below tensor as weights with three values.\"\"\"\n",
    "\n",
    "namedTensorWgts = torch.tensor([0.2126, 0.7152, 0.0722], names=['channels'])\n",
    "print(f'Named Tensor: {namedTensorWgts}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Converting Image Array into PyTorch Tensor.\"\"\"\n",
    "torchImage = torch.from_numpy(np_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we are assigning first dim as channel name, second dim as row and third dim as columns. It assigns name from right to left because the batch dimension is assigned as None. Batch Dimension varies according to users preference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchNamed = torchImage.refine_names(..., 'channels', 'rows', 'columns')\n",
    "print(\"Named Image Tensor:\", torchNamed.shape, torchNamed.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightsAligned = namedTensorWgts.align_as(torchNamed)\n",
    "print(f'Aligning Weight As Image {weightsAligned.shape}, {weightsAligned.names}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Manipulating Using Named Dimensions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Combining Channels to turn RGB into Gray Scale.\"\"\"\n",
    "\n",
    "grayNamed = (torchNamed * weightsAligned).sum('channels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(grayNamed, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Renaming the dimensions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grayPlain = grayNamed.rename(None)\n",
    "print(f'Renaming Gray Tensor as None: {grayPlain.shape}, {grayPlain.names}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Storage\n",
    "\n",
    "Tensor Storage makes pytorch quite fast. It assigns block of continous memory for each tensor (matrix or vector) and whenever operation like dimension changes are done, it happens within the same memory without assigning to any other block of memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**View Storage Object Of A Tensor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "print(f'No. Of Elements in a Tensor: {points.storage().size()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accessing Storage Location And Modifying Value Of A Tensor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points_storage = points.storage()\n",
    "points_storage[0] = 2.0\n",
    "print(f'Changing Value at Position 0 Of a Tensor from 4 to 2: \\n{points}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Storage Offset**\n",
    "\n",
    "Tensor's offset in the underlying storage in terms of number of storage elements (not bytes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "print(f\"Tensor's Offset: {points.storage_offset()} \\n\")\n",
    "\n",
    "first_point = points[0]\n",
    "print(f'Offset Of First Element Of The Tensor: {points[0]}')\n",
    "print(f\"First Element's Offset {first_point.storage_offset()} \\n\")\n",
    "\n",
    "second_point = points[1]\n",
    "print(f\"Offset Of Second Element Of The Tensor: {points[1]}\")\n",
    "print(f\"Second Element's Offset {second_point.storage_offset()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Tensor 'a' and reference it on 'b' tensor. Check if the storage is on the same memory block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating 'a' Tensor\n",
    "a = torch.arange(9).view(3,3)\n",
    "b = a.view(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#id is the unique id of a Specific Object\n",
    "id(a.storage)==id(b.storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stride \n",
    "\n",
    "It is the jump necessary to go from one element to the next one in the\n",
    "specified dimension `dim`. A tuple of all strides is returned when no\n",
    "argument is passed in. Otherwise, an integer value is returned as the stride in\n",
    "the particular dimension.\n",
    "\n",
    "**Find the Stride of a Tensor**\n",
    "\n",
    "In the below example, 'a' is a single dimension tensor. So every element is located next to each other by distance of 1 and their storage location is stored next to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(range(9))\n",
    "a = torch.tensor(a)\n",
    "print(a.stride(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Convert Vector Into Matrix\"\"\"\n",
    "a = a.view(3,3)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Storage and Stride**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage = a.storage()\n",
    "print(f'Storage Object of \\'a\\' Tensor:\\n{storage}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 'a' tensor, the stride at dim=0 is 3 because each element occupies 3 place, so the next element(sub-vector) is present at 3 storage places from first element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a.stride(dim=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 'a' tensor, the stride at dim=1 is 1 because each element is present next to each other with storage places next to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(f'Elements in Ist Dimension are present next to each other: {a.stride(dim=1)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accessing Elements Using Stride and Index**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = (2, 1)\n",
    "item = a[idx].item()\n",
    "print(f'Element to find: {item}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stride = a.stride()\n",
    "print(f'Stride at Each Dimension: {stride}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing Index and Stride Based Item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = idx[0]*stride[0] + idx[1]*stride[1]\n",
    "print(f'Is Element at indexed location is same as stride based location: {storage[loc]==item}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thanks For Reading. For Feedback, reach out on Github. Please don't spam."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
