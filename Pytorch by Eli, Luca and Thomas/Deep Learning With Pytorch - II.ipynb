{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification on CIFAR Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision.utils import save_image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading the dataset if not present using Torchvision Dataset Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Using Torchvision's Transform function, we transform images to tensor and normalize it with mean and std over each channel of the Image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))])\n",
    "trainset = torchvision.datasets.CIFAR10(root='/home/mayur/Desktop/Pytorch/data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "testset = torchvision.datasets.CIFAR10(root='/home/mayur/Desktop/Pytorch/data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking hierarchy of the class of CIFAR dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torchvision.datasets.cifar.CIFAR10,\n",
       " torchvision.datasets.vision.VisionDataset,\n",
       " torch.utils.data.dataset.Dataset,\n",
       " object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trainset).__mro__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading one Image and checking its label !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = trainset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_image(img, '/home/mayur/Desktop/Model_Deployment/sample_image.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIL_image = Image.open('/home/mayur/Desktop/Model_Deployment/sample_image.jpg')\n",
    "torch_img = transforms.ToTensor()(PIL_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Normalize Image\n",
    "\n",
    "Above in transforms section, I have used 0.5 as mean and std across 3 channels. The way to find the mean and std of an image with three channel.\n",
    "\n",
    "Why Normalize images for whole dataset ?\n",
    "\n",
    "https://stats.stackexchange.com/questions/211436/why-normalize-images-by-subtracting-datasets-image-mean-instead-of-the-current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = torch.stack([img_t for img_t, _ in trainset], dim=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32, 50000])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0172, -0.0357, -0.1070])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.view(3, -1).mean(dim=1) # Recall that view(3, -1) keeps the three channels and merges all the remaining dimensions into one, figuring out the appropriate size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4941, 0.4870, 0.5232])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.view(3, -1).std(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can replace mean and std with newly found values in transforms.Normalize()**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Classification Model\n",
    "\n",
    "**Create a Subset of full dataset by keeping only keeping two sets of images like birds and airplane.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label Mapping - classification of two class \n",
    "\n",
    "label_map = {0: 0, 2: 1}\n",
    "class_names = ['airplane', 'bird']\n",
    "cifar_2 = [(img, label_map[label1]) for img, label1 in trainset if label1 in [0,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar2_val = [(img, label_map[label])\n",
    "for img, label in testset\n",
    "if label in [0, 2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to flatten a matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_dimension = torch.randn(4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2354, -0.1260, -1.4139,  0.0181, -0.7167, -1.8803, -0.3555, -0.8785,\n",
       "        -0.5474,  0.3860, -2.0155,  0.5652,  0.9730,  0.1102,  1.4525, -0.5118,\n",
       "         1.2378, -0.9805,  0.3566, -0.8049])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_dimension.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2354, -0.1260, -1.4139,  0.0181, -0.7167],\n",
       "        [-1.8803, -0.3555, -0.8785, -0.5474,  0.3860],\n",
       "        [-2.0155,  0.5652,  0.9730,  0.1102,  1.4525],\n",
       "        [-0.5118,  1.2378, -0.9805,  0.3566, -0.8049]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**32 × 32 × 3: that is, 3,072 input features per sample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_feat = cifar_2[0][0].view(-1).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_out = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_model = nn.Sequential(\n",
    "    nn.Linear(i_feat, 512),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(512, n_out)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Representing the output using Probabilities, since the output is categorical. We can use softmax to bring down each class predicated value in range of 0 to 1.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return torch.exp(x)/ torch.exp(x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0900, 0.2447, 0.6652])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "x = torch.tensor([[1.0, 2.0, 3.0],\n",
    "[1.0, 2.0, 3.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0900, 0.2447, 0.6652],\n",
       "        [0.0900, 0.2447, 0.6652]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_model_smax = nn.Sequential(\n",
    "    clf_model,\n",
    "    nn.Softmax(dim=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=3072, out_features=512, bias=True)\n",
       "  (1): Tanh()\n",
       "  (2): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, _ = cifar_2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1327, -0.1389]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_batch = img.view(-1).unsqueeze(0)\n",
    "out = clf_model(img_batch)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, index = torch.max(out, dim=1)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_model_logSmax = nn.Sequential(\n",
    "    clf_model,\n",
    "    nn.LogSoftmax(dim=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6962, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, label = cifar_2[0]\n",
    "out = clf_model_logSmax(img.view(-1).unsqueeze(0))\n",
    "loss(out, torch.tensor([label]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why MSELoss is not good fit for Classification task? The loss tends to flatten at the extreme of the probability score or score of an predicted class. It means, the loss saturates(remain same) even though the predicted probability becomes worse or betters.** \n",
    "    \n",
    "        If loss = 100, at pp = 0.2, then loss would remain around ~100, even if pp=0.1. It doesn't penalizes the well for learning better parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FULL MODEL Without DATALOADER which means no Shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "model = nn.Sequential(nn.Linear(3072, 512),\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(512, 2),\n",
    "        nn.LogSoftmax(dim=1))\n",
    "\n",
    "learning_rate = 1e-2\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.NLLLoss()\n",
    "n_epochs = 10\n",
    "for epoch in range(n_epochs):\n",
    "    for img, label in cifar_2:\n",
    "        out = model(img.view(-1).unsqueeze(0))\n",
    "        loss = loss_fn(out, torch.tensor([label]))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))\n",
    "# Epoch: 9, Loss: 5.858117  \n",
    "# CPU times: user 54min 35s, sys: 3.08 s, total: 54min 38s\n",
    "# Wall time: 3min 39s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FULL MODEL WITH DATALOADER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.644894\n",
      "Epoch: 1, Loss: 0.588386\n",
      "Epoch: 2, Loss: 0.482380\n",
      "Epoch: 3, Loss: 0.396015\n",
      "Epoch: 4, Loss: 0.526204\n",
      "Epoch: 5, Loss: 0.333051\n",
      "Epoch: 6, Loss: 0.261083\n",
      "Epoch: 7, Loss: 0.318108\n",
      "Epoch: 8, Loss: 0.453247\n",
      "Epoch: 9, Loss: 0.314923\n",
      "Epoch: 10, Loss: 0.206487\n",
      "Epoch: 11, Loss: 0.601495\n",
      "Epoch: 12, Loss: 0.345804\n",
      "Epoch: 13, Loss: 0.299421\n",
      "Epoch: 14, Loss: 0.586524\n",
      "Epoch: 15, Loss: 0.412204\n",
      "Epoch: 16, Loss: 0.255649\n",
      "Epoch: 17, Loss: 0.595014\n",
      "Epoch: 18, Loss: 0.282063\n",
      "Epoch: 19, Loss: 0.506065\n",
      "Epoch: 20, Loss: 0.303293\n",
      "Epoch: 21, Loss: 0.264876\n",
      "Epoch: 22, Loss: 0.527000\n",
      "Epoch: 23, Loss: 0.365232\n",
      "Epoch: 24, Loss: 0.258177\n",
      "Epoch: 25, Loss: 0.492007\n",
      "Epoch: 26, Loss: 0.333968\n",
      "Epoch: 27, Loss: 0.205591\n",
      "Epoch: 28, Loss: 0.229390\n",
      "Epoch: 29, Loss: 0.423348\n",
      "Epoch: 30, Loss: 0.210544\n",
      "Epoch: 31, Loss: 0.280837\n",
      "Epoch: 32, Loss: 0.286746\n",
      "Epoch: 33, Loss: 0.323365\n",
      "Epoch: 34, Loss: 0.472793\n",
      "Epoch: 35, Loss: 0.200212\n",
      "Epoch: 36, Loss: 0.161071\n",
      "Epoch: 37, Loss: 0.266975\n",
      "Epoch: 38, Loss: 0.277691\n",
      "Epoch: 39, Loss: 0.285654\n",
      "Epoch: 40, Loss: 0.178291\n",
      "Epoch: 41, Loss: 0.222371\n",
      "Epoch: 42, Loss: 0.252928\n",
      "Epoch: 43, Loss: 0.450882\n",
      "Epoch: 44, Loss: 0.276784\n",
      "Epoch: 45, Loss: 0.400828\n",
      "Epoch: 46, Loss: 0.256691\n",
      "Epoch: 47, Loss: 0.211665\n",
      "Epoch: 48, Loss: 0.263066\n",
      "Epoch: 49, Loss: 0.379202\n",
      "Epoch: 50, Loss: 0.295797\n",
      "Epoch: 51, Loss: 0.531545\n",
      "Epoch: 52, Loss: 0.243412\n",
      "Epoch: 53, Loss: 0.116873\n",
      "Epoch: 54, Loss: 0.219244\n",
      "Epoch: 55, Loss: 0.265722\n",
      "Epoch: 56, Loss: 0.351581\n",
      "Epoch: 57, Loss: 0.174706\n",
      "Epoch: 58, Loss: 0.385579\n",
      "Epoch: 59, Loss: 0.393021\n",
      "Epoch: 60, Loss: 0.372322\n",
      "Epoch: 61, Loss: 0.155779\n",
      "Epoch: 62, Loss: 0.295122\n",
      "Epoch: 63, Loss: 0.273787\n",
      "Epoch: 64, Loss: 0.208351\n",
      "Epoch: 65, Loss: 0.102334\n",
      "Epoch: 66, Loss: 0.264598\n",
      "Epoch: 67, Loss: 0.244435\n",
      "Epoch: 68, Loss: 0.321537\n",
      "Epoch: 69, Loss: 0.203151\n",
      "Epoch: 70, Loss: 0.094846\n",
      "Epoch: 71, Loss: 0.179116\n",
      "Epoch: 72, Loss: 0.115136\n",
      "Epoch: 73, Loss: 0.148519\n",
      "Epoch: 74, Loss: 0.209930\n",
      "Epoch: 75, Loss: 0.063937\n",
      "Epoch: 76, Loss: 0.376635\n",
      "Epoch: 77, Loss: 0.065938\n",
      "Epoch: 78, Loss: 0.166367\n",
      "Epoch: 79, Loss: 0.126782\n",
      "Epoch: 80, Loss: 0.045750\n",
      "Epoch: 81, Loss: 0.144518\n",
      "Epoch: 82, Loss: 0.088463\n",
      "Epoch: 83, Loss: 0.092183\n",
      "Epoch: 84, Loss: 0.108148\n",
      "Epoch: 85, Loss: 0.071879\n",
      "Epoch: 86, Loss: 0.146536\n",
      "Epoch: 87, Loss: 0.105138\n",
      "Epoch: 88, Loss: 0.087856\n",
      "Epoch: 89, Loss: 0.111455\n",
      "Epoch: 90, Loss: 0.060303\n",
      "Epoch: 91, Loss: 0.198614\n",
      "Epoch: 92, Loss: 0.144532\n",
      "Epoch: 93, Loss: 0.074356\n",
      "Epoch: 94, Loss: 0.078271\n",
      "Epoch: 95, Loss: 0.111178\n",
      "Epoch: 96, Loss: 0.049363\n",
      "Epoch: 97, Loss: 0.188671\n",
      "Epoch: 98, Loss: 0.106275\n",
      "Epoch: 99, Loss: 0.081787\n",
      "CPU times: user 21min 24s, sys: 983 ms, total: 21min 25s\n",
      "Wall time: 1min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_loader = torch.utils.data.DataLoader(cifar_2, batch_size=64,shuffle=True)\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(3072, 512),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(512, 2),\n",
    "    nn.LogSoftmax(dim=1)\n",
    ")\n",
    "\n",
    "learning_rate = 1e-2\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.NLLLoss()\n",
    "n_epochs = 100\n",
    "for epoch in range(n_epochs):\n",
    "    for imgs, labels in train_loader:\n",
    "        batch_size = imgs.shape[0]\n",
    "        outputs = model(imgs.view(batch_size, -1))\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))\n",
    "\n",
    "# Epoch: 99, Loss: 0.032753   \n",
    "# CPU times: user 19min 32s, sys: 1.01 s, total: 19min 33s\n",
    "# Wall time: 1min 18s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: %f 0.8125\n"
     ]
    }
   ],
   "source": [
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        batch_size = imgs.shape[0]\n",
    "        outputs = model(imgs.view(batch_size, -1))\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "\n",
    "print(\"Accuracy: %f\",format( correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CrossEntropyLoss vs Negative Loglikehood**\n",
    "\n",
    "https://discuss.pytorch.org/t/difference-between-cross-entropy-loss-or-log-likelihood-loss/38816/2\n",
    "\n",
    "https://discuss.pytorch.org/t/is-log-softmax-nllloss-crossentropyloss/9352"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "nn.Linear(3072, 1024),\n",
    "nn.Tanh(),\n",
    "nn.Linear(1024, 512),\n",
    "nn.Tanh(),\n",
    "nn.Linear(512, 128),\n",
    "nn.Tanh(),\n",
    "nn.Linear(128, 2))\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.678014\n",
      "Epoch: 1, Loss: 0.677991\n",
      "Epoch: 2, Loss: 0.681271\n",
      "Epoch: 3, Loss: 0.683395\n",
      "Epoch: 4, Loss: 0.686967\n",
      "Epoch: 5, Loss: 0.683250\n",
      "Epoch: 6, Loss: 0.695043\n",
      "Epoch: 7, Loss: 0.672982\n",
      "Epoch: 8, Loss: 0.687277\n",
      "Epoch: 9, Loss: 0.678163\n",
      "Epoch: 10, Loss: 0.673666\n",
      "Epoch: 11, Loss: 0.697849\n",
      "Epoch: 12, Loss: 0.687613\n",
      "Epoch: 13, Loss: 0.670645\n",
      "Epoch: 14, Loss: 0.675446\n",
      "Epoch: 15, Loss: 0.675562\n",
      "Epoch: 16, Loss: 0.681900\n",
      "Epoch: 17, Loss: 0.689112\n",
      "Epoch: 18, Loss: 0.673557\n",
      "Epoch: 19, Loss: 0.684123\n",
      "Epoch: 20, Loss: 0.684820\n",
      "Epoch: 21, Loss: 0.689459\n",
      "Epoch: 22, Loss: 0.697348\n",
      "Epoch: 23, Loss: 0.688172\n",
      "Epoch: 24, Loss: 0.679374\n",
      "Epoch: 25, Loss: 0.679256\n",
      "Epoch: 26, Loss: 0.685537\n",
      "Epoch: 27, Loss: 0.682556\n",
      "Epoch: 28, Loss: 0.662182\n",
      "Epoch: 29, Loss: 0.672004\n",
      "Epoch: 30, Loss: 0.692190\n",
      "Epoch: 31, Loss: 0.688205\n",
      "Epoch: 32, Loss: 0.684494\n",
      "Epoch: 33, Loss: 0.678634\n",
      "Epoch: 34, Loss: 0.676054\n",
      "Epoch: 35, Loss: 0.677337\n",
      "Epoch: 36, Loss: 0.688876\n",
      "Epoch: 37, Loss: 0.697952\n",
      "Epoch: 38, Loss: 0.694994\n",
      "Epoch: 39, Loss: 0.684535\n",
      "Epoch: 40, Loss: 0.683753\n",
      "Epoch: 41, Loss: 0.674814\n",
      "Epoch: 42, Loss: 0.682374\n",
      "Epoch: 43, Loss: 0.696791\n",
      "Epoch: 44, Loss: 0.686631\n",
      "Epoch: 45, Loss: 0.688999\n",
      "Epoch: 46, Loss: 0.676616\n",
      "Epoch: 47, Loss: 0.671349\n",
      "Epoch: 48, Loss: 0.663920\n",
      "Epoch: 49, Loss: 0.664234\n",
      "Epoch: 50, Loss: 0.676606\n",
      "Epoch: 51, Loss: 0.693070\n",
      "Epoch: 52, Loss: 0.690542\n",
      "Epoch: 53, Loss: 0.680914\n",
      "Epoch: 54, Loss: 0.665810\n",
      "Epoch: 55, Loss: 0.695920\n",
      "Epoch: 56, Loss: 0.672099\n",
      "Epoch: 57, Loss: 0.692295\n",
      "Epoch: 58, Loss: 0.664208\n",
      "Epoch: 59, Loss: 0.674874\n",
      "Epoch: 60, Loss: 0.703515\n",
      "Epoch: 61, Loss: 0.681751\n",
      "Epoch: 62, Loss: 0.679794\n",
      "Epoch: 63, Loss: 0.686262\n",
      "Epoch: 64, Loss: 0.660121\n",
      "Epoch: 65, Loss: 0.680202\n",
      "Epoch: 66, Loss: 0.691573\n",
      "Epoch: 67, Loss: 0.682563\n",
      "Epoch: 68, Loss: 0.681332\n",
      "Epoch: 69, Loss: 0.687509\n",
      "Epoch: 70, Loss: 0.683600\n",
      "Epoch: 71, Loss: 0.689006\n",
      "Epoch: 72, Loss: 0.683790\n",
      "Epoch: 73, Loss: 0.685835\n",
      "Epoch: 74, Loss: 0.698711\n",
      "Epoch: 75, Loss: 0.703136\n",
      "Epoch: 76, Loss: 0.682644\n",
      "Epoch: 77, Loss: 0.672110\n",
      "Epoch: 78, Loss: 0.680912\n",
      "Epoch: 79, Loss: 0.690604\n",
      "Epoch: 80, Loss: 0.684707\n",
      "Epoch: 81, Loss: 0.681897\n",
      "Epoch: 82, Loss: 0.683213\n",
      "Epoch: 83, Loss: 0.697378\n",
      "Epoch: 84, Loss: 0.679575\n",
      "Epoch: 85, Loss: 0.696636\n",
      "Epoch: 86, Loss: 0.663791\n",
      "Epoch: 87, Loss: 0.683675\n",
      "Epoch: 88, Loss: 0.699221\n",
      "Epoch: 89, Loss: 0.701751\n",
      "Epoch: 90, Loss: 0.683167\n",
      "Epoch: 91, Loss: 0.697263\n",
      "Epoch: 92, Loss: 0.713198\n",
      "Epoch: 93, Loss: 0.683705\n",
      "Epoch: 94, Loss: 0.668659\n",
      "Epoch: 95, Loss: 0.687930\n",
      "Epoch: 96, Loss: 0.682834\n",
      "Epoch: 97, Loss: 0.686261\n",
      "Epoch: 98, Loss: 0.688093\n",
      "Epoch: 99, Loss: 0.677052\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "for epoch in range(n_epochs):\n",
    "    for imgs, labels in train_loader:\n",
    "        batch_size = imgs.shape[0]\n",
    "        outputs = model(imgs.view(batch_size, -1))\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: %f 0.5865\n"
     ]
    }
   ],
   "source": [
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        batch_size = imgs.shape[0]\n",
    "        outputs = model(imgs.view(batch_size, -1))\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "\n",
    "print(\"Accuracy: %f\",format( correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3737474, [3145728, 1024, 524288, 512, 65536, 128, 256, 2])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numel_list = [p.numel()\n",
    "for p in model.parameters()\n",
    "if p.requires_grad == True]\n",
    "sum(numel_list), numel_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Translation Invariant** Refer Book\n",
    "\n",
    "An airplane flying in the sky captured in a 32 × 32 image will be very roughly similar to\n",
    "a dark, cross-like shape on a blue background. A fully connected network as in figure\n",
    "7.15 would need to learn that when pixel 0,1 is dark, pixel 1,1 is also dark, and so on,\n",
    "that’s a good indication of an airplane. This is illustrated in the top half of figure 7.16.\n",
    "Shift the same airplane by one pixel or more as in the bottom half of the fig-\n",
    "ure, and the relationships between pixels will have to be relearned from scratch: this\n",
    "time, an airplane is likely when pixel 0,2 is dark, pixel 1,2 is dark, and so on. In more\n",
    "technical terms, a fully connected network is not translation invariant. This means a\n",
    "network that has been trained to recognize a Spitfire starting at position 4,4 will not\n",
    "be able to recognize the exact same Spitfire starting at position 8,8. We would then have\n",
    "to augment the dataset—that is, apply random translations to images during training—\n",
    "so the network would have a chance to see Spitfires all over the image, and we would\n",
    "need to do this for every image in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(3, 16, kernel_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = cifar_2[0]\n",
    "img = img.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 32, 32])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = conv(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 30, 30])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## The dimension are reduced bcz of kernel. \n",
    "plt.imshow(out[0, 0].detach(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img[0,0].detach(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_pad = nn.Conv2d(3, 16, kernel_size=3, padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 32, 32])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, label = cifar_2[0]\n",
    "img = img.unsqueeze(0)\n",
    "out = conv_pad(img)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 32, 32]), torch.Size([1, 3, 16, 16]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool = nn.MaxPool2d(2)\n",
    "output = pool(img)\n",
    "img.shape, output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "nn.Tanh(),\n",
    "nn.MaxPool2d(2),\n",
    "nn.Conv2d(16, 8, kernel_size=3, padding=1),\n",
    "nn.Tanh(),\n",
    "nn.MaxPool2d(2),\n",
    "# ...\n",
    "nn.Linear(8 * 8 * 8, 32),\n",
    "nn.Tanh(),\n",
    "nn.Linear(32, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18090, [432, 16, 1152, 8, 16384, 32, 64, 2])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numel_list = [p.numel() for p in model.parameters()]\n",
    "sum(numel_list), numel_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Convolution Model using nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.act1 = nn.Tanh()\n",
    "        self.max1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.act2 = nn.Tanh()\n",
    "        self.max2 = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.act3 = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.max1(self.act1(self.conv1(x)))\n",
    "        out = self.max2(self.act2(self.conv2(out)))\n",
    "        out = out.view(-1, 8 * 8 * 8) # in above model ... was missing this line !\n",
    "        out = self.act3(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18090, [432, 16, 1152, 8, 16384, 32, 64, 2])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = net()\n",
    "numel_list = [p.numel() for p in model.parameters()]\n",
    "sum(numel_list), numel_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3C * 3 * 3 * 16 = 432 #16 Output Channel - From Conv1 Layer\n",
    "\n",
    "16C = 16 # tanh\n",
    "\n",
    "16C * 3 * 3 * 8 = 1152 #8 Output Channel - From Conv2 Layer\n",
    "\n",
    "8C = 8 # tanh\n",
    "\n",
    "8C * 8H * 8W * 32 = 16384 #32 Output Channel from Linear Layer 1\n",
    "\n",
    "32C = 32 # tanh\n",
    "\n",
    "32C * 2 = 64 #2 Output Layer from Linear Layer 2\n",
    "\n",
    "2 Class Probabilities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "net(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (act1): Tanh()\n",
       "  (max1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (act2): Tanh()\n",
       "  (max2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=512, out_features=32, bias=True)\n",
       "  (act3): Tanh()\n",
       "  (fc2): Linear(in_features=32, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.Conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.Conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(8*8*8, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.Conv1(x)),2)\n",
    "        out = F.max_pool2d(torch.tanh(self.Conv2(out)),2)\n",
    "        out = out.view(-1, 8 * 8 * 8)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1333, 0.2398]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        \"\"\"\n",
    "        Loops over our dataset in the batches the data loader creates for us\n",
    "        \"\"\"\n",
    "        for imgs, labels in train_loader:\n",
    "            #Feeds a batch through our model ...\n",
    "            outputs = model(imgs)\n",
    "            \n",
    "            # ... and computes the loss we wish to minimize\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            #After getting rid of the gradients from the last round ...\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            #... performs the backward step. That is, we compute the gradients of all parameters we want the network to learn.\n",
    "            loss.backward()\n",
    "            \n",
    "            # Updates the model\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_train += loss.item()\n",
    "            \n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "            datetime.datetime.now(), epoch,\n",
    "            loss_train / len(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar_2, batch_size=64,\n",
    "shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-17 16:37:20.686576 Epoch 1, Training loss 0.6239917893318614\n",
      "2020-07-17 16:37:31.812774 Epoch 10, Training loss 0.35999924969521296\n",
      "2020-07-17 16:37:44.041104 Epoch 20, Training loss 0.31443331718065176\n",
      "2020-07-17 16:37:57.989455 Epoch 30, Training loss 0.2892987493686615\n",
      "2020-07-17 16:38:11.323510 Epoch 40, Training loss 0.2684701074175774\n",
      "2020-07-17 16:38:24.219665 Epoch 50, Training loss 0.25094598731037915\n",
      "2020-07-17 16:38:36.345529 Epoch 60, Training loss 0.23674602550306137\n",
      "2020-07-17 16:38:49.225030 Epoch 70, Training loss 0.22076270715066582\n",
      "2020-07-17 16:39:02.234376 Epoch 80, Training loss 0.20623055717368036\n",
      "2020-07-17 16:39:15.187303 Epoch 90, Training loss 0.1959344895592161\n",
      "2020-07-17 16:39:28.161248 Epoch 100, Training loss 0.18336010524991211\n",
      "CPU times: user 29min 32s, sys: 42.6 s, total: 30min 14s\n",
      "Wall time: 2min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "training_loop(\n",
    "n_epochs = 100,\n",
    "optimizer = optimizer,\n",
    "model = model,\n",
    "loss_fn = loss_fn,\n",
    "train_loader = train_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.90\n",
      "Accuracy val: 0.86\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar_2, batch_size=64,\n",
    "shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,\n",
    "shuffle=False)\n",
    "def validate(model, train_loader, val_loader):\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in loader:\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim=1)\n",
    "                total += labels.shape[0]\n",
    "                correct += int((predicted == labels).sum())\n",
    "                \n",
    "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
    "        \n",
    "validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model/\" + 'birds_vs_airplanes.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = Net()\n",
    "loaded_model.load_state_dict(torch.load(\"model/\" + 'birds_vs_airplanes.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img, label = cifar2_val[0]\n",
    "\n",
    "# loaded_model.eval()\n",
    "# with torch.no_grad():\n",
    "    \n",
    "#     output = loaded_model(img.unsqueeze(0))\n",
    "#     _, predicted = torch.max(output, dim=1)\n",
    "#     print(predicted.item())\n",
    "#     print(class_names[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img.permute(1,2,0))\n",
    "plt.savefig('/home/mayur/Desktop/Model_Deployment/plane.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on Cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device cuda.\n"
     ]
    }
   ],
   "source": [
    "device = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
    "print(f\"Training on device {device}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        \"\"\"\n",
    "        Loops over our dataset in the batches the data loader creates for us\n",
    "        \"\"\"\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs = imgs.to(device=device)\n",
    "            labels = labels.to(device=device)\n",
    "            \n",
    "            #Feeds a batch through our model ...\n",
    "            outputs = model(imgs)\n",
    "            \n",
    "            # ... and computes the loss we wish to minimize\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            #After getting rid of the gradients from the last round ...\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            #... performs the backward step. That is, we compute the gradients of all parameters we want the network to learn.\n",
    "            loss.backward()\n",
    "            \n",
    "            # Updates the model\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_train += loss.item()\n",
    "            \n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "            datetime.datetime.now(), epoch,\n",
    "            loss_train / len(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar_2, batch_size=64,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-12 20:22:51.042898 Epoch 1, Training loss 0.605764420358998\n",
      "2020-07-12 20:22:53.365773 Epoch 10, Training loss 0.37257426768351515\n",
      "2020-07-12 20:22:55.966001 Epoch 20, Training loss 0.3153013024170687\n",
      "2020-07-12 20:22:58.715658 Epoch 30, Training loss 0.28940475907675023\n",
      "2020-07-12 20:23:01.296965 Epoch 40, Training loss 0.2707495789049537\n",
      "2020-07-12 20:23:03.887686 Epoch 50, Training loss 0.24903670987885468\n",
      "2020-07-12 20:23:06.472710 Epoch 60, Training loss 0.23125037270936238\n",
      "2020-07-12 20:23:09.055006 Epoch 70, Training loss 0.21709420465549845\n",
      "2020-07-12 20:23:11.648606 Epoch 80, Training loss 0.20504711554118782\n",
      "2020-07-12 20:23:14.227783 Epoch 90, Training loss 0.18978152884419558\n",
      "2020-07-12 20:23:16.784610 Epoch 100, Training loss 0.1784428007853259\n",
      "CPU times: user 25.9 s, sys: 266 ms, total: 26.2 s\n",
      "Wall time: 26.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(\n",
    "n_epochs = 100,\n",
    "optimizer = optimizer,\n",
    "model = model,\n",
    "loss_fn = loss_fn,\n",
    "train_loader = train_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ways to Reduce Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop_l2reg(n_epochs, optimizer, model, loss_fn,\n",
    "train_loader):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "            \n",
    "            imgs = imgs.to(device=device)\n",
    "            labels = labels.to(device=device)\n",
    "            \n",
    "            outputs = model(imgs)\n",
    "            \n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            l2_lambda = 0.001\n",
    "            l2_norm = sum(p.pow(2.0).sum() for p in model.parameters()) # Replaces pow(2.0) with abs() for L1 regularization\n",
    "            loss = loss + l2_lambda * l2_norm\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_train += loss.item()\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "            datetime.datetime.now(), epoch,\n",
    "            loss_train / len(train_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetDropout(nn.Module):\n",
    "    def __init__(self, n_chans1=32):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.conv1_dropout = nn.Dropout2d(p=0.4)\n",
    "        self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size=3,\n",
    "        padding=1)\n",
    "        self.conv2_dropout = nn.Dropout2d(p=0.4)\n",
    "        self.fc1 = nn.Linear(8 * 8 * n_chans1 // 2, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = self.conv1_dropout(out)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = self.conv2_dropout(out)\n",
    "        out = out.view(-1, 8 * 8 * self.n_chans1 // 2)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Distribution of Weights of trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = [p.view(-1) for p in model.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgt = param[7].cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 5., 13., 44., 80., 75., 81., 73., 51.,  7.,  3.]),\n",
       " array([-0.46112216, -0.369093  , -0.27706388, -0.18503472, -0.09300558,\n",
       "        -0.00097643,  0.09105272,  0.18308187,  0.27511102,  0.36714014,\n",
       "         0.4591693 ], dtype=float32),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(wgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 1., 2., 2., 0., 3., 1., 1., 3., 2.]),\n",
       " array([-0.34008625, -0.29337847, -0.24667071, -0.19996293, -0.15325515,\n",
       "        -0.10654738, -0.0598396 , -0.01313183,  0.03357594,  0.08028372,\n",
       "         0.1269915 ], dtype=float32),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(wgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 15.,  56., 150., 238., 303., 229., 115.,  36.,   4.,   6.]),\n",
       " array([-0.2555791 , -0.19547646, -0.1353738 , -0.07527114, -0.01516848,\n",
       "         0.04493418,  0.10503684,  0.1651395 ,  0.22524217,  0.2853448 ,\n",
       "         0.34544748], dtype=float32),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(wgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 1., 0., 0., 1., 0., 1., 1., 1.]),\n",
       " array([-0.2366386 , -0.20400186, -0.17136511, -0.13872837, -0.10609162,\n",
       "        -0.07345487, -0.04081813, -0.00818138,  0.02445536,  0.05709211,\n",
       "         0.08972885], dtype=float32),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(wgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  23.,  102.,  718., 3423., 4971., 4727., 2046.,  321.,   44.,\n",
       "           9.]),\n",
       " array([-0.14312217, -0.11343018, -0.08373819, -0.05404621, -0.02435423,\n",
       "         0.00533776,  0.03502975,  0.06472173,  0.09441371,  0.1241057 ,\n",
       "         0.15379769], dtype=float32),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(wgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 1., 5., 4., 6., 5., 4., 3., 0., 3.]),\n",
       " array([-0.12240616, -0.10064252, -0.07887886, -0.05711522, -0.03535157,\n",
       "        -0.01358792,  0.00817573,  0.02993938,  0.05170303,  0.07346667,\n",
       "         0.09523033], dtype=float32),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(wgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.,  5.,  8., 12.,  3., 12.,  8., 11.,  3.,  1.]),\n",
       " array([-0.759473  , -0.60569566, -0.45191833, -0.29814097, -0.14436363,\n",
       "         0.00941372,  0.16319107,  0.3169684 ,  0.47074577,  0.6245231 ,\n",
       "         0.77830046], dtype=float32),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(wgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " array([-1.0878402e-01, -8.7036297e-02, -6.5288581e-02, -4.3540858e-02,\n",
       "        -2.1793138e-02, -4.5418739e-05,  2.1702301e-02,  4.3450020e-02,\n",
       "         6.5197743e-02,  8.6945459e-02,  1.0869318e-01], dtype=float32),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(wgt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Normalization - \n",
    "\n",
    "Batch normalization is to rescale the inputs to the activa-\n",
    "tions of the network so that minibatches have a certain desirable distribution. Recall-\n",
    "ing the mechanics of learning and the role of nonlinear activation functions, this\n",
    "helps avoid the inputs to activation functions being too far into the saturated portion\n",
    "of the function, thereby killing gradients and slowing training.\n",
    "In practical terms, batch normalization shifts and scales an intermediate input\n",
    "using the mean and standard deviation collected at that intermediate location over\n",
    "the samples of the minibatch. The regularization effect is a result of the fact that an\n",
    "individual sample and its downstream activations are always seen by the model as\n",
    "shifted and scaled, depending on the statistics across the randomly extracted mini-\n",
    "batch. This is in itself a form of principled augmentation.\n",
    "\n",
    "Since the aim for batch normalization is to rescale the inputs of the activa-\n",
    "tions, the natural location is after the linear transformation (convolution, in this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetBatchNorm(nn.Module):\n",
    "    def __init__(self, n_chans1=32):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.conv1_batchnorm = nn.BatchNorm2d(num_features=n_chans1)\n",
    "        self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size=3,\n",
    "        padding=1)\n",
    "        self.conv2_batchnorm = nn.BatchNorm2d(num_features=n_chans1 // 2)\n",
    "        self.fc1 = nn.Linear(8 * 8 * n_chans1 // 2, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "    def forward(self, x):\n",
    "        out = self.conv1_batchnorm(self.conv1(x))\n",
    "        out = F.max_pool2d(torch.tanh(out), 2)\n",
    "        out = self.conv2_batchnorm(self.conv2(out))\n",
    "        out = F.max_pool2d(torch.tanh(out), 2)\n",
    "        out = out.view(-1, 8 * 8 * self.n_chans1 // 2)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Depth of Neural Networks\n",
    "\n",
    "**As the depth of the network increase the gradients tends to move to zero, causing Vanishing Gradient Problem, which is over come by Skip Conections**\n",
    "\n",
    "**A skip connection is nothing but the addition of the input to the output of a block of layers. This is exactly how it is done in PyTorch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetDepth(nn.Module):\n",
    "    def __init__(self, n_chans1=32):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size=3,\n",
    "        padding=1)\n",
    "        self.conv3 = nn.Conv2d(n_chans1 // 2, n_chans1 // 2,\n",
    "        kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(4 * 4 * n_chans1 // 2, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n",
    "        out = F.max_pool2d(torch.relu(self.conv3(out)), 2)\n",
    "        out = out.view(-1, 4 * 4 * self.n_chans1 // 2)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Idea of adding skip connection was originated from residual networks (Resnet). Adding a skip connection a la ResNet to this model amounts to adding the output of the first layer in the forward function to the input of the third layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetRes(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_chans1=32):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size=3,\n",
    "        padding=1)\n",
    "        self.conv3 = nn.Conv2d(n_chans1 // 2, n_chans1 // 2,\n",
    "        kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(4 * 4 * n_chans1 // 2, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n",
    "        out1 = out\n",
    "        out = F.max_pool2d(torch.relu(self.conv3(out)) + out1, 2)\n",
    "        out = out.view(-1, 4 * 4 * self.n_chans1 // 2)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "    \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*What's happening above ?*\n",
    "\n",
    "**In other words, we’re using the output of the first activations as inputs to the last, in\n",
    "addition to the standard feed-forward path. This is also referred to as identity mapping.**\n",
    "\n",
    "*So, how does this alleviate the issues with vanishing gradients we were mentioning\n",
    "earlier?*\n",
    "\n",
    "**Thinking about backpropagation, we can appreciate that a skip connection, or a\n",
    "sequence of skip connections in a deep network, creates a direct path from the deeper\n",
    "parameters to the loss. This makes their contribution to the gradient of the loss more\n",
    "direct, as partial derivatives of the loss with respect to those parameters have a chance\n",
    "not to be multiplied by a long chain of other operations.\n",
    "It has been observed that skip connections have a beneficial effect on convergence\n",
    "especially in the initial phases of training. Also, the loss landscape of deep residual\n",
    "networks is a lot smoother than feed-forward networks of the same depth and width.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building 100 Layer Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, n_chans):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(n_chans, n_chans, kernel_size=3,\n",
    "        padding=1, bias=False)\n",
    "        self.batch_norm = nn.BatchNorm2d(num_features=n_chans)\n",
    "        torch.nn.init.kaiming_normal_(self.conv.weight,\n",
    "        nonlinearity='relu')\n",
    "        torch.nn.init.constant_(self.batch_norm.weight, 0.5)\n",
    "        torch.nn.init.zeros_(self.batch_norm.bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.batch_norm(out)\n",
    "        out = torch.relu(out)\n",
    "        \n",
    "        return out + x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BatchNorm layer would cancel the effect of bias, so it is customarily left out, as in bias=False.\n",
    "\n",
    "Uses custom initializations\n",
    ". kaiming_normal_ initializes with\n",
    "normal random elements with standard\n",
    "deviation as computed in the ResNet paper.\n",
    "The batch norm is initialized to produce output\n",
    "distributions that initially have 0 mean and 0.5 variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetResDeep(nn.Module):\n",
    "    def __init__(self, n_chans1=32, n_blocks=10):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.resblocks = nn.Sequential(\n",
    "        *(n_blocks * [ResBlock(n_chans=n_chans1)]))\n",
    "        self.fc1 = nn.Linear(8 * 8 * n_chans1, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = self.resblocks(out)\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = out.view(-1, 8 * 8 * self.n_chans1)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Keeping Images intact with padding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 28, 28])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_pad = nn.Conv2d(3, 32, kernel_size=5, padding=2)\n",
    "img, label = cifar_2[0]\n",
    "img = img.unsqueeze(0)\n",
    "out = conv_pad(img)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Exercises -> width - kernel_size + 1\n",
    "class NN_Model(nn.Module):\n",
    "    def __init__(self, n_channel):\n",
    "        super().__init__()\n",
    "        self.n_channel = n_channel\n",
    "        self.conv1 = nn.Conv2d(3, n_channel, kernel_size=5, padding=2)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=n_channel)\n",
    "        self.conv2 = nn.Conv2d(n_channel, n_channel//2, kernel_size=5, padding=2)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=n_channel//2)\n",
    "        self.fc1 = nn.Linear(8 * 8 * n_channel//2 , 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.bn1(self.conv1(x))\n",
    "        out = F.max_pool2d(torch.tanh(out), 2)\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out = F.max_pool2d(torch.tanh(out), 2)\n",
    "        out = out.view(-1, 8 * 8 * self.n_channel // 2)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "fresh_model = NN_Model(n_channel=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        loss_train = 0.0\n",
    "        for img, label in train_loader:\n",
    "            img = img.to('cuda')\n",
    "            label = label.to('cuda')\n",
    "            output = model(img)\n",
    "            \n",
    "            loss = loss_fn(output, label)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch: {epoch}, Loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NN_Model(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(16, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (bn2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=512, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fresh_model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Loss: 0.6395094990730286\n",
      "Epoch: 20, Loss: 0.6124091148376465\n",
      "Epoch: 30, Loss: 0.6007277965545654\n",
      "Epoch: 40, Loss: 0.5745313763618469\n",
      "Epoch: 50, Loss: 0.5408896207809448\n",
      "Epoch: 60, Loss: 0.5111746788024902\n",
      "Epoch: 70, Loss: 0.48889583349227905\n",
      "Epoch: 80, Loss: 0.4641161262989044\n",
      "Epoch: 90, Loss: 0.43953585624694824\n",
      "Epoch: 100, Loss: 0.41507869958877563\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(fresh_model.parameters(), lr=1e-3)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(n_epochs = 100,optimizer = optimizer,model = fresh_model,loss_fn = loss,train_loader = train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.89\n",
      "Accuracy val: 0.88\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar_2, batch_size=64,\n",
    "shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,\n",
    "shuffle=False)\n",
    "def validate(model, train_loader, val_loader):\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in loader:\n",
    "                imgs = imgs.to('cuda')\n",
    "                labels = labels.to('cuda')\n",
    "                outputs = fresh_model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim=1)\n",
    "                total += labels.shape[0]\n",
    "                correct += int((predicted == labels).sum())\n",
    "                \n",
    "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
    "        \n",
    "validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing Kernel from 5,5 to 1,3 - Lookout for padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 32, 32])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_pad = nn.Conv2d(3, 32, kernel_size=(1,3), padding=(0,1))\n",
    "img, label = cifar_2[0]\n",
    "img = img.unsqueeze(0)\n",
    "out = conv_pad(img)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Exercises -> width - kernel_size + 1\n",
    "class NN_Model_K(nn.Module):\n",
    "    def __init__(self, n_channel):\n",
    "        super().__init__()\n",
    "        self.n_channel = n_channel\n",
    "        self.conv1 = nn.Conv2d(3, n_channel, kernel_size=(1,3), padding=(0,1))\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=n_channel)\n",
    "        self.conv2 = nn.Conv2d(n_channel, n_channel//2, kernel_size=(1,3), padding=(0,1))\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=n_channel//2)\n",
    "        self.fc1 = nn.Linear(8 * 8 * n_channel//2 , 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.bn1(self.conv1(x))\n",
    "        out = F.max_pool2d(torch.relu(out), 2)\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out = F.max_pool2d(torch.relu(out), 2)\n",
    "        out = out.view(-1, 8 * 8 * self.n_channel // 2)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "fresh_model_k = NN_Model_K(n_channel=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        loss_train = 0.0\n",
    "        for img, label in train_loader:\n",
    "            img = img.to('cuda')\n",
    "            label = label.to('cuda')\n",
    "            output = model(img)\n",
    "            \n",
    "            loss = loss_fn(output, label)\n",
    "            \n",
    "            loss_train += loss.item()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "            datetime.datetime.now(), epoch,\n",
    "            loss_train / len(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NN_Model_K(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
       "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(32, 16, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
       "  (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=1024, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fresh_model_k.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-20 10:34:04.579627 Epoch 1, Training loss 0.6357857163544673\n",
      "2020-07-20 10:34:07.567076 Epoch 10, Training loss 0.3856166413255558\n",
      "2020-07-20 10:34:10.708750 Epoch 20, Training loss 0.3382227804250778\n",
      "2020-07-20 10:34:13.773509 Epoch 30, Training loss 0.3110316048382194\n",
      "2020-07-20 10:34:16.855919 Epoch 40, Training loss 0.2933084041259851\n",
      "2020-07-20 10:34:19.871960 Epoch 50, Training loss 0.28022247780660153\n",
      "2020-07-20 10:34:23.029456 Epoch 60, Training loss 0.26937293104685034\n",
      "2020-07-20 10:34:26.018041 Epoch 70, Training loss 0.25972320096697776\n",
      "2020-07-20 10:34:29.084593 Epoch 80, Training loss 0.2507866209574566\n",
      "2020-07-20 10:34:32.138758 Epoch 90, Training loss 0.24222446081175167\n",
      "2020-07-20 10:34:35.166683 Epoch 100, Training loss 0.23400165069444923\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(fresh_model_k.parameters(), lr=1e-3)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "train_loader = torch.utils.data.DataLoader(cifar_2, batch_size=64,shuffle=False)\n",
    "training_loop(n_epochs = 100,optimizer = optimizer,model = fresh_model_k,loss_fn = loss,train_loader = train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.90\n",
      "Accuracy val: 0.88\n"
     ]
    }
   ],
   "source": [
    "\n",
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,\n",
    "shuffle=False)\n",
    "def validate(model, train_loader, val_loader):\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in loader:\n",
    "                imgs = imgs.to('cuda')\n",
    "                labels = labels.to('cuda')\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim=1)\n",
    "                total += labels.shape[0]\n",
    "                correct += int((predicted == labels).sum())\n",
    "                \n",
    "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
    "        \n",
    "validate(fresh_model_k, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(fresh_model_k.state_dict(), \"/home/mayur/Desktop/Model_Deployment/model/\" + 'birds_vs_airplanes.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
