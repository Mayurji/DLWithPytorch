{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.nn import functional as F\n",
    "import torchvision.transforms.functional as transFunc\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple CNN with no regualarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Clf(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 32, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(32*8*8, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(F.relu(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 32*8*8)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_Clf(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=2048, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN_Clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN with Dropout\n",
    "\n",
    "**Dropout:** what if we just don’t train a random bunch of nodes within the network during a training cycle? Because they won’t be updated, they won’t have the chance to overfit to the input data, and because it’s random, each training cycle will ignore a different selection of the input, which should help generalization even further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Clf_do(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 32, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(32*8*8, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        self.dropout = nn.Dropout2d(p=0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(F.relu(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 32*8*8)\n",
    "        out = self.dropout(F.relu(self.fc1(out)))\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_Clf_do(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=2048, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=2, bias=True)\n",
       "  (dropout): Dropout2d(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN_Clf_do()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN with BatchNorm\n",
    "\n",
    "BatchNorm, short for batch normalization, is a simple layer that has one task in life: using two learned parameters (meaning that it will be trained along with the rest of the network) to try to ensure that each minibatch that goes through the network has a mean centered around zero with a variance of 1. You might ask why we need to do this when we’ve already normalized our input by using the transform chain in Chapter 2. For smaller networks, BatchNorm is indeed less useful, but as they get larger, the effect of any layer on another, say 20 layers down, can be vast because of repeated multiplication, and you may end up with either vanishing or exploding gradients, both of which are fatal to the training process. The BatchNorm layers make sure that even if you use a model such as ResNet-152, the multiplications inside your network don’t get out of hand.\n",
    "\n",
    "You might be wondering: if we have BatchNorm in our network, why are we normalizing the input at all in the training loop’s transformation chain? After all, shouldn’t BatchNorm do the work for us? And the answer here is yes, you could do that! But it’ll take longer for the network to learn how to get the inputs under control, as they’ll have to discover the initial transform themselves, which will make training longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Clf_BN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=32)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=32)       \n",
    "        self.fc1 = nn.Linear(32*8*8, 32)\n",
    "        self.bn3 = nn.BatchNorm1d(num_features=32) \n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(F.relu(self.bn1(self.conv1(x))), 2)\n",
    "        out = F.max_pool2d(F.relu(self.bn2(self.conv2(out))), 2)\n",
    "        out = out.view(-1, 32*8*8)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = self.fc2(self.bn3(out))\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_Clf_BN(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=2048, out_features=32, bias=True)\n",
       "  (bn3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=32, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN_Clf_BN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))])\n",
    "trainset = torchvision.datasets.CIFAR10(root='/home/mayur/Desktop/Pytorch/data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n",
    "                                          shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "testset = torchvision.datasets.CIFAR10(root='/home/mayur/Desktop/Pytorch/data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label Mapping - classification of two class \n",
    "\n",
    "#CIFAR has 10 classes, we are restricting it into 2 classes\n",
    "label_map = {0: 0, 2: 1}\n",
    "class_names = ['airplane', 'bird']\n",
    "cifar_2 = [(img, label_map[label1]) for img, label1 in trainset if label1 in [0,2]]\n",
    "cifar2_val = [(img, label_map[label]) for img, label in testset if label in [0, 2]]\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(cifar_2, batch_size=64,shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_fn, trainloader, testloader, n_epochs, device):\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        training_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        model.train()\n",
    "        for batch in trainloader:\n",
    "            img, label = batch\n",
    "            img = img.to(device)\n",
    "            label = label.to(device)\n",
    "            \n",
    "            output = model(img)\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_fn(output, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            training_loss += loss.data.item()\n",
    "        training_loss /= len(trainset)\n",
    "        \n",
    "        model.eval()\n",
    "        num_correct = 0\n",
    "        num_examples = 0\n",
    "        for batch in testloader:\n",
    "            img, label = batch\n",
    "            img = img.to(device)\n",
    "            label = label.to(device)\n",
    "            \n",
    "            output = model(img)\n",
    "            loss = loss_fn(output, label)\n",
    "            valid_loss += loss.data.item()\n",
    "            correct = torch.eq(torch.max(F.softmax(output),dim=1)[1], label).view(-1)\n",
    "            num_correct += torch.sum(correct).item()\n",
    "            num_examples += correct.shape[0]\n",
    "            \n",
    "        valid_loss/=len(testset)\n",
    "        \n",
    "        print(f'Epoch: {epoch}, Training Loss: {training_loss:.3f}, Validation Loss: {valid_loss:.3f}, Accuracy: {num_correct/num_examples}')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:31: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 0.001, Validation Loss: 0.001, Accuracy: 0.832\n",
      "Epoch: 2, Training Loss: 0.001, Validation Loss: 0.001, Accuracy: 0.8695\n",
      "Epoch: 3, Training Loss: 0.001, Validation Loss: 0.001, Accuracy: 0.867\n",
      "Epoch: 4, Training Loss: 0.001, Validation Loss: 0.001, Accuracy: 0.8925\n",
      "Epoch: 5, Training Loss: 0.001, Validation Loss: 0.001, Accuracy: 0.9035\n",
      "Epoch: 6, Training Loss: 0.001, Validation Loss: 0.001, Accuracy: 0.905\n",
      "Epoch: 7, Training Loss: 0.001, Validation Loss: 0.001, Accuracy: 0.903\n",
      "Epoch: 8, Training Loss: 0.001, Validation Loss: 0.001, Accuracy: 0.8905\n",
      "Epoch: 9, Training Loss: 0.000, Validation Loss: 0.001, Accuracy: 0.9065\n",
      "Epoch: 10, Training Loss: 0.000, Validation Loss: 0.001, Accuracy: 0.876\n",
      "Epoch: 11, Training Loss: 0.000, Validation Loss: 0.001, Accuracy: 0.9035\n",
      "Epoch: 12, Training Loss: 0.000, Validation Loss: 0.001, Accuracy: 0.898\n",
      "Epoch: 13, Training Loss: 0.000, Validation Loss: 0.001, Accuracy: 0.905\n",
      "Epoch: 14, Training Loss: 0.000, Validation Loss: 0.001, Accuracy: 0.897\n",
      "Epoch: 15, Training Loss: 0.000, Validation Loss: 0.001, Accuracy: 0.9035\n",
      "Epoch: 16, Training Loss: 0.000, Validation Loss: 0.001, Accuracy: 0.894\n",
      "Epoch: 17, Training Loss: 0.000, Validation Loss: 0.001, Accuracy: 0.9015\n",
      "Epoch: 18, Training Loss: 0.000, Validation Loss: 0.001, Accuracy: 0.901\n",
      "Epoch: 19, Training Loss: 0.000, Validation Loss: 0.001, Accuracy: 0.904\n",
      "Epoch: 20, Training Loss: 0.000, Validation Loss: 0.001, Accuracy: 0.904\n"
     ]
    }
   ],
   "source": [
    "### CNN\n",
    "net = CNN_Clf()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "net.to(device)\n",
    "train(net, optimizer, torch.nn.CrossEntropyLoss(), trainloader, testloader, n_epochs=20, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:31: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 0.001, Validation Loss: 0.001, Accuracy: 0.862\n",
      "Epoch: 2, Training Loss: 0.001, Validation Loss: 0.001, Accuracy: 0.8665\n",
      "Epoch: 3, Training Loss: 0.001, Validation Loss: 0.001, Accuracy: 0.8825\n",
      "Epoch: 4, Training Loss: 0.001, Validation Loss: 0.001, Accuracy: 0.892\n",
      "Epoch: 5, Training Loss: 0.001, Validation Loss: 0.001, Accuracy: 0.8865\n",
      "Epoch: 6, Training Loss: 0.001, Validation Loss: 0.001, Accuracy: 0.872\n",
      "Epoch: 7, Training Loss: 0.001, Validation Loss: 0.001, Accuracy: 0.899\n",
      "Epoch: 8, Training Loss: 0.001, Validation Loss: 0.001, Accuracy: 0.9055\n",
      "Epoch: 9, Training Loss: 0.001, Validation Loss: 0.001, Accuracy: 0.911\n",
      "Epoch: 10, Training Loss: 0.001, Validation Loss: 0.001, Accuracy: 0.9025\n",
      "Epoch: 11, Training Loss: 0.000, Validation Loss: 0.001, Accuracy: 0.91\n",
      "Epoch: 12, Training Loss: 0.000, Validation Loss: 0.001, Accuracy: 0.912\n",
      "Epoch: 13, Training Loss: 0.000, Validation Loss: 0.001, Accuracy: 0.909\n",
      "Epoch: 14, Training Loss: 0.000, Validation Loss: 0.001, Accuracy: 0.8975\n",
      "Epoch: 15, Training Loss: 0.000, Validation Loss: 0.001, Accuracy: 0.909\n",
      "Epoch: 16, Training Loss: 0.000, Validation Loss: 0.001, Accuracy: 0.911\n",
      "Epoch: 17, Training Loss: 0.000, Validation Loss: 0.001, Accuracy: 0.9125\n",
      "Epoch: 18, Training Loss: 0.000, Validation Loss: 0.001, Accuracy: 0.916\n",
      "Epoch: 19, Training Loss: 0.000, Validation Loss: 0.001, Accuracy: 0.913\n",
      "Epoch: 20, Training Loss: 0.000, Validation Loss: 0.001, Accuracy: 0.916\n"
     ]
    }
   ],
   "source": [
    "### CNN\n",
    "net = CNN_Clf_do()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "net.to(device)\n",
    "train(net, optimizer, torch.nn.CrossEntropyLoss(), trainloader, testloader, n_epochs=20, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:31: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 0.001, Validation Loss: 0.001, Accuracy: 0.868\n",
      "Epoch: 2, Training Loss: 0.001, Validation Loss: 0.001, Accuracy: 0.834\n",
      "Epoch: 3, Training Loss: 0.001, Validation Loss: 0.001, Accuracy: 0.871\n",
      "Epoch: 4, Training Loss: 0.001, Validation Loss: 0.001, Accuracy: 0.8905\n",
      "Epoch: 5, Training Loss: 0.001, Validation Loss: 0.001, Accuracy: 0.8875\n",
      "Epoch: 6, Training Loss: 0.001, Validation Loss: 0.001, Accuracy: 0.8935\n",
      "Epoch: 7, Training Loss: 0.001, Validation Loss: 0.001, Accuracy: 0.9045\n",
      "Epoch: 8, Training Loss: 0.001, Validation Loss: 0.001, Accuracy: 0.9055\n",
      "Epoch: 9, Training Loss: 0.000, Validation Loss: 0.001, Accuracy: 0.8995\n",
      "Epoch: 10, Training Loss: 0.000, Validation Loss: 0.001, Accuracy: 0.889\n",
      "Epoch: 11, Training Loss: 0.000, Validation Loss: 0.001, Accuracy: 0.907\n",
      "Epoch: 12, Training Loss: 0.000, Validation Loss: 0.001, Accuracy: 0.892\n",
      "Epoch: 13, Training Loss: 0.000, Validation Loss: 0.001, Accuracy: 0.9015\n",
      "Epoch: 14, Training Loss: 0.000, Validation Loss: 0.001, Accuracy: 0.8905\n",
      "Epoch: 15, Training Loss: 0.000, Validation Loss: 0.001, Accuracy: 0.8725\n",
      "Epoch: 16, Training Loss: 0.000, Validation Loss: 0.001, Accuracy: 0.899\n",
      "Epoch: 17, Training Loss: 0.000, Validation Loss: 0.001, Accuracy: 0.8745\n",
      "Epoch: 18, Training Loss: 0.000, Validation Loss: 0.001, Accuracy: 0.89\n",
      "Epoch: 19, Training Loss: 0.000, Validation Loss: 0.001, Accuracy: 0.896\n",
      "Epoch: 20, Training Loss: 0.000, Validation Loss: 0.001, Accuracy: 0.8975\n"
     ]
    }
   ],
   "source": [
    "### CNN\n",
    "net = CNN_Clf_BN()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "net.to(device)\n",
    "train(net, optimizer, torch.nn.CrossEntropyLoss(), trainloader, testloader, n_epochs=20, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
