{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch\n",
    "\n",
    "PyTorch is a popular open source machine learning library based on Torch library. Pytorch provides three set of libraries, i.e., torchvision, torchaudio, torchtext for Computer Vision, Audio and Text respectively.\n",
    "\n",
    "It provides two high-level features:\n",
    "\n",
    "* Tensor computation (like NumPy) with strong GPU acceleration\n",
    "* Deep neural networks built on a type-based autograd system\n",
    "\n",
    "### Topics Covered\n",
    "\n",
    "- Introducing Batch Dimension.\n",
    "- Load Batch Of Images (Not Recommended Approach).\n",
    "- Normalization\n",
    "    - Resize.\n",
    "    - Standardization.\n",
    "    - Plotting.\n",
    "- Creating One-Hot Encoding.\n",
    "    - Convert Vector Into One-Hot Encoded Matrix.\n",
    "    - Sample Example On Scatter_ with Zero and One Dimension.\n",
    "    - Filter observation based on Condition.\n",
    "- Norm\n",
    "    - L2 Norm\n",
    "    - L1 Norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open('SampleImages/dog.jpg')\n",
    "np_image = np.rollaxis(np.asarray(image), 2, 0)\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(f'Numpy Image Shape: {np_image.shape}')\n",
    "torchImage = torch.from_numpy(np_image)\n",
    "print(f'Convert Numpy to PyTorch: {torchImage.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pytorch format for image is C * H * W\n",
    "* Convert numpy into PyTorch Format\n",
    "* If the image is not in required format, then we can use Permute to align the dimension as required by pytorch, it moves dimension as mentioned in permute.\n",
    "\n",
    "If you've built a deep learning model, during training, we should mention the batch size of the data. Now, we have seen that an image has three dimension. So there must be another dimension(batch), which needs to be included.\n",
    "\n",
    "**Note: Sometimes images also have an alpha channel indicating transparency.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducing Batch Dimension\n",
    "\n",
    "**Since we have only one image, we have batch size of 1. Unsqueeze introduces the dimension along with position in the argument. Standard practice is to keep the batch dimension at first position.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Batch Dimension at First Position: {torchImage.unsqueeze(0).shape}')\n",
    "print(f'Batch Dimension at Second Position: {torchImage.unsqueeze(1).shape}')\n",
    "print(f'Batch Dimension at Last Position: {torchImage.unsqueeze(-1).shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Batch Of Images (Not Recommended Approach)\n",
    "\n",
    "Declaring Zero matrix of an Image Dimension with constant resolution and batch dimension. Here, we are creating block of tensor to handle the batch of images. But torchvision library provides dataloader to load bulk of images. We will create dataloader in the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Creating a batch of three image.\"\"\"\n",
    "batch_size = 3\n",
    "imageBatch = torch.zeros(batch_size, 3, 256, 256, dtype=torch.int16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can insert three images into this batch tensor. \n",
    "\n",
    "* Moving a set of three images of different dimensions into imageBatch.\n",
    "* We should resize the dimensions of the image to imageBatch dimension.\n",
    "\n",
    "A bunch of things are happening in the below cell\n",
    "\n",
    "- We are only selecting \"jpg\" files.\n",
    "- Iterating through image folder and generating corresponding path for each image.\n",
    "- Resizing each image w.r.t imageBatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'SampleImages'\n",
    "filenames = [name for name in os.listdir(data) if os.path.splitext(name)[-1] == '.jpg']\n",
    "pilImages = [Image.open(os.path.join(data, f)) for f in filenames[:]]\n",
    "f = lambda: [img.resize((256, 256)) for img in pilImages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Converting the PIL to Numpy Array, from Numpy to Torch. There is other way around for conversion from PIL to Torch image using torchvision library.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, file in enumerate(f()):\n",
    "    file = np.asarray(file)\n",
    "    file = torch.from_numpy(file).permute(2, 0, 1)\n",
    "    imageBatch[i] = file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We have three images in a imageBatch Tensor with resized dimension to 256x256.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageBatch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "\n",
    "Normalization is a common Machine Learning concept applied on the features to  scale down the values. Normalization on images can be done by finding the image's mean and standard deviation.\n",
    "\n",
    "**One way to normalize a grayscale image is image/=255.0**\n",
    "\n",
    "In the below cell, we perform **Standardization**. A series of steps are followed here\n",
    "\n",
    "- Convert Int type tensor to float tensor.\n",
    "- Get the number of channels in the Image.\n",
    "- Iterate through each channel.\n",
    "- Calculate mean and standard deviation by combining three image's channel iteratively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Second way to Normalize, It is technically called as Standardization.\n",
    "imageBatch = imageBatch.float()\n",
    "\n",
    "n_channels = imageBatch.shape[1]\n",
    "for c in range(n_channels):\n",
    "    mean = torch.mean(imageBatch[:, c])\n",
    "    std = torch.std(imageBatch[:, c])\n",
    "    imageBatch[:, c] = (imageBatch[:, c] - mean) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(1,2, figsize=(10,10))\n",
    "axarr[0].imshow(np.asarray(pilImages[0]))\n",
    "axarr[1].imshow(imageBatch[0].permute(1,2,0))\n",
    "axarr[0].set(xlabel=\"Original\")\n",
    "axarr[1].set(xlabel=\"Edited-256x256 and Standardized\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding\n",
    "\n",
    "To handle categorical variables like class names or text feature etc, we use one hot encoding.\n",
    "We create a vector of 25 rows and then plug a value 1 at each index along the dimension mentioned in _scatter. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Converting Vector Into One-Hot Encoded Matrix**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps to convert a vector into one-hot encoding.\n",
    "\n",
    "- Create a Vector.\n",
    "- Create zero matrix with unique categories present in vector.\n",
    "- Converting 1D Vector into 2D Matrix Using unsqueeze.\n",
    "- torch scatter_ writes values on the indices as mentioned by vector.\n",
    "- scatter_ method's first argument of 1 refers to dimension. \n",
    "    - If one, it sets 1.0 along column dimension.\n",
    "    - If zero, it sets 1.0 along row dimension.\n",
    "- Mapping value 1.0 to Indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = torch.randint(0, 5, (25,))\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_onehot = torch.zeros(vector.shape[0], len(vector.unique()))\n",
    "target_onehot.scatter_(1, vector.unsqueeze(1), 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Example On Scatter_ with Zero and One Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = torch.arange(1, 11).reshape((2, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = torch.tensor([[0, 1, 2, 0]])\n",
    "torch.zeros(3, 5, dtype=src.dtype).scatter_(0, index, src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = torch.tensor([[0, 1, 2, 0]])\n",
    "torch.zeros(3, 5, dtype=src.dtype).scatter_(1, index, src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = torch.tensor([[0, 1, 3], [0, 1, 4]])\n",
    "torch.zeros(3, 5, dtype=src.dtype).scatter_(1, index, src)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filtering records based on condition.**\n",
    "\n",
    "Consider we have 25 observations with 10 features and a target variable, we can assume the previously created vector as target variable. If we can filter observations based on target value as mentioned in the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We find the index of the vector with values less than or equal to two \n",
    "and utilize those indexes to get relevant observation.\n",
    "\"\"\"\n",
    "data = torch.randn(25, 10)\n",
    "print(f'Total Observation: {data.shape}')\n",
    "bad_index = vector<=2\n",
    "bad_data = data[bad_index]\n",
    "print(f'Filtered Observations: {bad_data.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Norm of a Vector\n",
    "\n",
    "**In Machine Learning, we often hear about norm of a vector. It refers to magnitude or length of a vector in the vector space.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**L2 Norm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = torch.tensor([3.0, -4.0])\n",
    "print(f'L2 Norm of a Vector: {torch.norm(u, p=2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**L1 Norm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = torch.tensor([3.0, -4.0])\n",
    "print(f'L1 Norm of a Vector: {torch.norm(u, p=1)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thanks For Reading. For Feedback, reach out on Github. Please don't spam."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
