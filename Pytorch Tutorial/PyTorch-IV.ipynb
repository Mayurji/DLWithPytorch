{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch\n",
    "\n",
    "PyTorch is a popular open source machine learning library based on Torch library. Pytorch provides three set of libraries, i.e., torchvision, torchaudio, torchtext for Computer Vision, Audio and Text respectively.\n",
    "\n",
    "It provides two high-level features:\n",
    "\n",
    "* Tensor computation (like NumPy) with strong GPU acceleration.\n",
    "* Deep neural networks built on a type-based autograd system.\n",
    "\n",
    "**Topic Covered**\n",
    "\n",
    " - <strong>Handling Time Series Data</strong>\n",
    " - <strong>Handling Text Data</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working on Time Series Data\n",
    "\n",
    "We use [Bike sharing](https://www.kaggle.com/c/bike-sharing-demand/data) data from kaggle given for a two year period. Though, the objective of the dataset is to predict the count of bikes rented during each hour, but here we are going to learn how to handle time series dataset using pytorch.\n",
    "\n",
    "* Loading dataset using Numpy\n",
    "* Skip the column names\n",
    "* Convert string to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Years Data\n",
    "bikes_numpy = np.loadtxt(\"data/hour-fixed.csv\",dtype=np.float32,\n",
    "              delimiter=\",\",skiprows=1, converters={1: lambda x: float(x[8:10])})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Convert numpy to pytorch tensor.\n",
    "* Check after how many elements the next(second) records starts from zero offset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Total Obervations: {bikes_numpy.shape} \\n')\n",
    "bikes = torch.from_numpy(bikes_numpy)\n",
    "print(f'A Jump of 17 element in 1st dimension is required to go from one observation to next observation {bikes.stride()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the Dataset into features\n",
    "\n",
    "* **Convert the hour based into days as 1st dim, 24 hours as 2nd dim and 17 features as 3rd dim. It is quite common to reshape the timeseries data to find seasonality or trends.**\n",
    "* 17520 / (2 * 365 * 24) = 1.0. (2 years, 365 Days, 24 hours - Total Number of Observations.)\n",
    "* The original data is presented on hour bases.\n",
    "* We have 2 years data, 730 days, each day has 24 hours and each hour has 17 columns/features.\n",
    "* We convert the hours into days, which becomes our records or rows. Each row or record is further segregated among hours our second dim.\n",
    "* Each row in second dim contains 17 elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_bikes = bikes.view(-1, 24, bikes.shape[1])\n",
    "print(f'Reshaped Time Series Dataset: {daily_bikes.shape} \\n')\n",
    "print(f'Stride for the current data structure: {daily_bikes.stride()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stride : 24 * 17 = 408\n",
    "\n",
    "N: 730 days\n",
    "\n",
    "* Reshaping the data to make it available for training purpose.\n",
    "* Converting Class into One Hot encoding\n",
    "* Stride value (408, 17, 1), it means to jump from one day (24x17 elements) to next day records, we need to jump 408 elements (feature values)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Since prediction requires count of rent biker per hour, we transpose the feature dimensions.** Below we are performing a series of steps.\n",
    "\n",
    "- Selecting 24 rows.\n",
    "- Creating empty matrix with 24 rows for weather feature.(categorical variable)\n",
    "- Creating One-Hot Encoder Vector for weather feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_bikes = daily_bikes.transpose(1, 2)\n",
    "print(f'After Transpose: {daily_bikes.shape, daily_bikes.stride()} \\n')\n",
    "first_day = bikes[:24].long()\n",
    "weather_onehot = torch.zeros(first_day.shape[0], 4) #4 is count of categories\n",
    "print(f'Weather Feature (categorical): {first_day[:,9]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Would encourage reader's to take up previous pytorch notebooks to understand better.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'One-Hot Encoded Weather Feature \\n{weather_onehot.scatter_(dim=1,index=first_day[:,9].unsqueeze(1).long() - 1,value=1.0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Combining the one hot encoded matrix with feature matrix.**\n",
    "* **Creating Empty matrix to accomdate all the weather feature as one-hot encoder.**\n",
    "* **Creating Zero Matrix for Class label.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Using cat method, we concat two matrix. Combining first 24 obsersations and \n",
    "its feature with weather's one-hot encoded vectors.\n",
    "\"\"\"\n",
    "\n",
    "combinedFeature = torch.cat((bikes[:24], weather_onehot), 1) \n",
    "print(f'After combining features (17 feature is turned into 21 feature after one-hot encoding): {combinedFeature.shape}\\n')\n",
    "\n",
    "daily_weather_onehot = torch.zeros(daily_bikes.shape[0], 4, daily_bikes.shape[2])\n",
    "print(f'Zero Matrix to accomdate weather\\'s one-hot encoding {daily_weather_onehot.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Turning Zero Empty matrix into One-Hot Encoded feature.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_weather_onehot.scatter_(1, daily_bikes[:,9,:].long().unsqueeze(1) - 1, 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Combining the existing and one-hot encoded features.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_bikes = torch.cat((daily_bikes, daily_weather_onehot), dim=1)\n",
    "print(f'Time Series Dataset: {daily_bikes.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Keeping Temp values between [0, 1] with min-max Scaling.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = daily_bikes[:, 10, :]\n",
    "temp_min = torch.min(temp)\n",
    "temp_max = torch.max(temp)\n",
    "daily_bikes[:, 10, :] = ((daily_bikes[:, 10, :] - temp_min) / (temp_max - temp_min))\n",
    "print(f'Min-Max Scaled: {daily_bikes[:,10,:]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Standardization of Temperature Feature****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = daily_bikes[:, 10, :]\n",
    "# daily_bikes[:, 10, :] = ((daily_bikes[:, 10, :] - torch.mean(temp))\n",
    "# / torch.std(temp))\n",
    "# print(f'Standardized Temperature Feature: {daily_bikes[:,10,:]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character Level Conversion\n",
    "\n",
    "There are 128 Ascii character, we convert our text/letter into index or integer. Letters not present in ASCII are turned into 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/anna.txt\", encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Converting text document into list of lines.\n",
    "* Fetching One Line by Index\n",
    "* Creating Matrix based on length of line and total number of characters possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = text.split(\"\\n\")\n",
    "print(f'Total Number of Lines: {len(lines)} \\n')\n",
    "line = lines[100]\n",
    "letter_t = torch.zeros(len(line), 128)\n",
    "print(f'Number of characters in a line x Total No. of Characters Possible: {letter_t.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating Character Matrix for a line. All ASCII characters are features, and each character from a line is separate observation. Since each observation is one character, we have that particular feature as 1 and other features as 0.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, letter in enumerate(line.lower().strip()):\n",
    "    letter_index = ord(letter) if ord(letter) < 128 else 0\n",
    "    #print(letter_index)\n",
    "    letter_t[i][letter_index] = 1\n",
    "    \n",
    "print(f'Character Matrix: {letter_t[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Column Number of the Feature In Character Matrix: {(letter_t[0]==1).nonzero(as_tuple=True)} \\n')\n",
    "\n",
    "print(f'First Character of the line: {ord(line[0])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Level Conversion\n",
    "\n",
    "* Clean the text\n",
    "* Sorting the text\n",
    "* Mapping the words into integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_words(input_str):\n",
    "    punctuation = '.,;:\"!?”“_-'\n",
    "    word_list = input_str.lower().replace('\\n',' ').split()\n",
    "    word_list = [word.strip(punctuation) for word in word_list]\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cleaning and Tokenization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_in_line = clean_words(line)\n",
    "line, words_in_line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15K+ words are present in the text after cleaning. We are mapping each word with an unique id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = sorted(set(clean_words(text)))\n",
    "word2index_dict = {word: i for (i, word) in enumerate(word_list)}\n",
    "print(f'Total Number Of Unique Words: {len(word2index_dict.keys())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Creating a Matrix where columns size is length of all words and each row is length of each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_t = torch.zeros(len(words_in_line), len(word2index_dict))\n",
    "word_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Index of each word on the column axis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, word in enumerate(words_in_line):\n",
    "    word_index = word2index_dict[word]\n",
    "    word_t[i][word_index] = 1\n",
    "    print('{:2} {:4} {}'.format(i, word_index, word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Word Matrix: \\n{word_t}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thanks For Reading. For Feedback, reach out on Github. Please don't spam."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
